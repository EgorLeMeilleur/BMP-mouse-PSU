{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "import cv2\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "folder_path = \"20230530_segm_black_mouse_mnSLA_red_and_black_back\"\n",
    "\n",
    "seed_value = 52\n",
    "torch.manual_seed(seed_value)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation():\n",
    "    count_image = 350\n",
    "    path_images = \"20230530_segm_black_mouse_mnSLA_red_and_black_back/images\"\n",
    "    path_masks = \"20230530_segm_black_mouse_mnSLA_red_and_black_back/masks\"\n",
    "\n",
    "    image_files = os.listdir(path_images)\n",
    "    selected_files_for_vertical = random.sample(image_files, count_image)\n",
    "\n",
    "    for filename in selected_files_for_vertical:\n",
    "        image_path = os.path.join(path_images, filename)\n",
    "        image = Image.open(image_path)\n",
    "        rotated_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        output_path = os.path.join(path_images, f'revert_vertical_{filename}')\n",
    "        rotated_image.save(output_path)\n",
    "        image.close()\n",
    "\n",
    "        mask_path = os.path.join(path_masks, filename)\n",
    "        mask = Image.open(mask_path)\n",
    "        rotated_mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        output_path = os.path.join(path_masks, f'revert_vertical_{filename}')\n",
    "        rotated_mask.save(output_path)\n",
    "        mask.close()\n",
    "\n",
    "    # selected_files_for_horizontal = []\n",
    "    count_image = 1\n",
    "    selected_files_for_horizontal = random.sample(image_files, count_image)\n",
    "\n",
    "    for filename in selected_files_for_horizontal:\n",
    "        image_path = os.path.join(path_images, filename)\n",
    "        image = Image.open(image_path)\n",
    "        rotated_image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        output_path = os.path.join(path_images, f'revert_horizontal_{filename}')\n",
    "        rotated_image.save(output_path)\n",
    "        image.close()\n",
    "\n",
    "        mask_path = os.path.join(path_masks, filename)\n",
    "        mask = Image.open(mask_path)\n",
    "        rotated_mask = mask.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        output_path = os.path.join(path_masks, f'revert_horizontal_{filename}')\n",
    "        rotated_mask.save(output_path)\n",
    "        mask.close()\n",
    "\n",
    "    return selected_files_for_vertical, selected_files_for_horizontal\n",
    "\n",
    "\n",
    "def delete_generated_images(data_vert, data_hor):\n",
    "    path_images = \"20230530_segm_black_mouse_mnSLA_red_and_black_back/images\"\n",
    "    path_masks = \"20230530_segm_black_mouse_mnSLA_red_and_black_back/masks\"\n",
    "\n",
    "    for filename in data_vert:\n",
    "        output_image_path = os.path.join(path_images, f'revert_vertical_{filename}')\n",
    "        os.remove(output_image_path)\n",
    "\n",
    "        output_mask_path = os.path.join(path_masks, f'revert_vertical_{filename}')\n",
    "        os.remove(output_mask_path)\n",
    "\n",
    "    for filename in data_hor:\n",
    "        output_image_path = os.path.join(path_images, f'revert_horizontal_{filename}')\n",
    "        os.remove(output_image_path)\n",
    "\n",
    "        output_mask_path = os.path.join(path_masks, f'revert_horizontal_{filename}')\n",
    "        os.remove(output_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_files(folder_path, folder):\n",
    "    images_folder = folder_path + \"/\" + folder + \"images\"\n",
    "    masks_folder = folder_path + \"/\" + folder + \"masks\"\n",
    "\n",
    "    images_files = os.listdir(images_folder)\n",
    "    masks_files = os.listdir(masks_folder)\n",
    "\n",
    "    image_paths = [os.path.join(folder + \"images\", file) for file in images_files]\n",
    "    mask_paths = [os.path.join(folder + \"masks\", file) for file in masks_files]\n",
    "\n",
    "    data = {'orig_image': image_paths, 'mask_image': mask_paths}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    csv_file_path = \"train_data.csv\" if folder == \"\" else \"test_data.csv\"\n",
    "\n",
    "    df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(orig_image, orig_masks, mask_image, intersec_mask):\n",
    "    fig, axes = plt.subplots(1, 4)\n",
    "\n",
    "    orig_image = orig_image.transpose(1, 2, 0)\n",
    "    orig_image = (np.array(orig_image) - np.min(orig_image)) / (np.max(orig_image) - np.min(orig_image))\n",
    "    axes[0].imshow(orig_image)\n",
    "    axes[0].set_title('Original Image')\n",
    "\n",
    "    axes[1].imshow(orig_masks)\n",
    "    axes[1].set_title('Original Mask')\n",
    "    \n",
    "    axes[2].imshow(mask_image)\n",
    "    axes[2].set_title('Predicted Mask')\n",
    "\n",
    "    axes[3].imshow(intersec_mask)\n",
    "    axes[3].set_title('Difference Mask')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(predictions, targets):\n",
    "    total_sum = 0.0\n",
    "    for prediction, target in zip(predictions, targets):\n",
    "        intersection = np.logical_and(prediction, target).sum().item()\n",
    "        union = np.logical_or(prediction, target).sum().item()\n",
    "        \n",
    "        total_sum += intersection / union if union > 0 else 0.0\n",
    "\n",
    "    return total_sum / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_k(predictions, targets, k, klass):\n",
    "    precision = 0\n",
    "    tp = 0\n",
    "    all_det = 0\n",
    "    for i in range(k):\n",
    "        predict = predictions[i]\n",
    "        target = targets[i]\n",
    "\n",
    "        if klass:\n",
    "            tp += np.sum(predict[predict == target])\n",
    "            all_det += np.sum(predict)\n",
    "            precision += tp / all_det\n",
    "        else:\n",
    "            tp += len(predict[predict == target]) - np.count_nonzero(predict[predict == target])\n",
    "            all_det += predict.size - np.count_nonzero(predict)\n",
    "            precision += tp / all_det\n",
    "    return precision / k \n",
    "\n",
    "def compute_ap(predictions, targets, k):\n",
    "    return (ap_k(predictions, targets, k, True) + ap_k(predictions, targets, k, False)) / 2, ap_k(predictions, targets, k, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(ground_truth_map):\n",
    "  y_indices, x_indices = np.where(ground_truth_map > 0)\n",
    "  x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "  y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "  H, W = ground_truth_map.shape\n",
    "  x_min = max(0, x_min - np.random.randint(0, 20))\n",
    "  x_max = min(W, x_max + np.random.randint(0, 20))\n",
    "  y_min = max(0, y_min - np.random.randint(0, 20))\n",
    "  y_max = min(H, y_max + np.random.randint(0, 20))\n",
    "  bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "  return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vertical, data_horizontal = augmentation()\n",
    "make_csv_files(folder_path, \"\")\n",
    "make_csv_files(folder_path, \"test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = os.listdir('20230530_segm_black_mouse_mnSLA_red_and_black_back/images')\n",
    "train_masks = os.listdir('20230530_segm_black_mouse_mnSLA_red_and_black_back/masks')\n",
    "test_images = os.listdir('20230530_segm_black_mouse_mnSLA_red_and_black_back/test_images')\n",
    "test_masks = os.listdir('20230530_segm_black_mouse_mnSLA_red_and_black_back/test_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset_dict = {\n",
    "    \"image\": [Image.open(img) for img in train_images],\n",
    "    \"label\": [Image.open(mask) for mask in train_labels],\n",
    "}\n",
    "\n",
    "val_dataset_dict = {\n",
    "    \"image\": [Image.open(img) for img in val_images],\n",
    "    \"label\": [Image.open(mask) for mask in val_labels],\n",
    "}\n",
    "\n",
    "test_dataset_dict = {\n",
    "    \"image\": [Image.open(img) for img in test_images],\n",
    "    \"label\": [Image.open(mask) for mask in test_masks],\n",
    "}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_dataset_dict)\n",
    "val_dataset = Dataset.from_dict(val_dataset_dict)\n",
    "test_dataset = Dataset.from_dict(test_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAMDataset(Dataset):\n",
    "  def __init__(self, dataset, processor):\n",
    "    self.dataset = dataset\n",
    "    self.processor = processor\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = self.dataset[idx]\n",
    "    image = item[\"image\"]\n",
    "    ground_truth_mask = np.array(item[\"label\"])\n",
    "\n",
    "    prompt = get_bounding_box(ground_truth_mask)\n",
    "\n",
    "    inputs = self.processor(image, input_boxes=[[prompt]], return_tensors=\"pt\")\n",
    "\n",
    "    inputs = {k:v.squeeze(0) for k,v in inputs.items()}\n",
    "\n",
    "    inputs[\"ground_truth_mask\"] = ground_truth_mask\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(num_epochs, train_load, val_load, model, optimizer, criterion, model_name, scheduler=None):\n",
    "  train_losses = []\n",
    "  val_losses = []\n",
    "  iou_test = []\n",
    "  max_iou = 0.0\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_load):\n",
    "        outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                      input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                      multimask_output=False)\n",
    "\n",
    "        predicted_masks = outputs.pred_masks.squeeze(1)\n",
    "        ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "        loss = criterion(predicted_masks, ground_truth_masks.unsqueeze(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss/len(train_load))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "      scheduler.step(loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_load):\n",
    "          outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                      input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                      multimask_output=False)\n",
    "\n",
    "          predicted_masks = outputs.pred_masks.squeeze(1)\n",
    "          ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "          loss = criterion(predicted_masks, ground_truth_masks.unsqueeze(1))\n",
    "          val_loss += (loss.item())\n",
    "    val_losses.append(val_loss/len(val_load))\n",
    "\n",
    "    predictions, _, orig_masks, _ = prediction(model, test_loader)\n",
    "    iou = calculate_iou(predictions, orig_masks)\n",
    "    iou_test.append(iou)\n",
    "\n",
    "    if iou > max_iou:\n",
    "       max_iou = iou\n",
    "       torch.save(model.state_dict(), f\"models/{model_name}_IOU-{iou}.pth\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, IOU: {iou:.4f}\")\n",
    "  return model, train_losses, val_losses, iou_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    orig_images = []\n",
    "    orig_masks = []\n",
    "    intersection_masks = []\n",
    "    size = (544, 928)\n",
    "    transform = transforms.Compose([transforms.Resize(size)])\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            outputs = model(pixel_values=batch[\"pixel_values\"].to(device),\n",
    "                      input_boxes=batch[\"input_boxes\"].to(device),\n",
    "                      multimask_output=False)\n",
    "\n",
    "            predicted_masks = outputs.pred_masks.squeeze(1)\n",
    "            ground_truth_masks = batch[\"ground_truth_mask\"].float().to(device).unsqueeze(1)\n",
    "\n",
    "            #new_outputs = torch.zeros(prediction_masks.shape[0], prediction_masks.shape[1], prediction_masks.shape[2], prediction_masks.shape[3])\n",
    "            predicted_masks[predicted_masks < 0] = 0\n",
    "            predicted_masks[predicted_masks > 0] = 1\n",
    "\n",
    "            # for i in range(outputs.shape[0]):\n",
    "            #     for j in range(outputs.shape[2]):\n",
    "            #         for k in range(outputs.shape[3]):\n",
    "            #             if outputs[i, 0, j, k] == 1:\n",
    "            #                 for m in range(-1, 2):\n",
    "            #                     for n in range(-1, 2):\n",
    "            #                         if 0 <= j + m < outputs.shape[2] - 4 and 0 <= k + n < outputs.shape[3] - 4:\n",
    "            #                             new_outputs[i, 0, j + 1 + m, k + 1 + n] = 1\n",
    "\n",
    "            # outputs = new_outputs\n",
    "\n",
    "            predicted_masks = transform(predicted_masks)\n",
    "            orig_images = transform(batch[\"pixel_values\"].float().unsqueeze(1))\n",
    "            orig_masks = transform(ground_truth_masks)\n",
    "\n",
    "            predictions.append(predicted_masks.cpu().numpy())\n",
    "            orig_images.append(orig_images.cpu().numpy())\n",
    "            orig_masks.append(orig_masks.cpu().numpy())\n",
    "\n",
    "            intersection = np.abs(predicted_masks.cpu().numpy() - orig_masks.cpu().numpy())\n",
    "            intersection_masks.append(intersection)\n",
    "    predictions = np.concatenate(predictions, axis=0).squeeze()\n",
    "    orig_images = np.concatenate(orig_images, axis=0).squeeze()\n",
    "    orig_masks = np.concatenate(orig_masks, axis=0).squeeze()\n",
    "    intersection_masks = np.concatenate(intersection_masks, axis=0).squeeze()\n",
    "    return predictions, orig_images, orig_masks, intersection_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, images_to_draw):\n",
    "    predictions, orig_images, orig_masks, intersection_masks = prediction(model, loader)\n",
    "\n",
    "    iou = calculate_iou(predictions, orig_masks)\n",
    "    apk, ap = compute_ap(predictions, orig_masks, len(predictions))\n",
    "\n",
    "    print(f\"IOU: {iou}\")\n",
    "    print(f\"AP for Two Classes: {apk}\")\n",
    "    print(f\"AP for Mouse Class: {ap}\")\n",
    "\n",
    "    for i in range(images_to_draw):\n",
    "        draw(orig_images[i], orig_masks[i], predictions[i], intersection_masks[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SamProcessor\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = SAMDataset(dataset=train_dataset, processor=processor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_dataset = SAMDataset(dataset=val_dataset, processor=processor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_dataset = SAMDataset(dataset=test_dataset, processor=processor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SamModel\n",
    "\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n",
    "model_name = \"sam-vit-base\"\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "        param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import monai \n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "optimizer = Adam(model.mask_decoder.parameters(), lr=lr, weight_decay=0)\n",
    "criterion = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_losses, val_losses, iou_test = learning(num_epochs, train_loader, val_loader, model, optimizer, criterion, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_losses, label='Training Losses', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(val_losses, label='Validation Losses', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(iou_test, label='IOU test', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('IOU Losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(model, train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(model, val_loader, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(model, test_loader, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
